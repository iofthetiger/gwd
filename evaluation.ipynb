{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch starter - FasterRCNN Inference\n",
    "\n",
    "- You can find the [train notebook here](https://www.kaggle.com/pestipeti/pytorch-starter-fasterrcnn-train)\n",
    "- The weights are [available here](https://www.kaggle.com/dataset/7d5f1ed9454c848ecb909c109c6fa8e573ea4de299e249c79edc6f47660bf4c5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from numba import jit\n",
    "import numba\n",
    "\n",
    "DIR_INPUT = '/home/hy/dataset/gwd'\n",
    "DIR_TRAIN = f'{DIR_INPUT}/train'\n",
    "DIR_TEST = f'{DIR_INPUT}/test'\n",
    "\n",
    "DIR_WEIGHTS = '/home/hy/kaggle/gwd'\n",
    "\n",
    "WEIGHTS_FILE = f'{DIR_WEIGHTS}/0513_fasterrcnn_resnet50_fpn.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147793, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(f'{DIR_INPUT}/train.csv')\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['x'] = -1\n",
    "train_df['y'] = -1\n",
    "train_df['w'] = -1\n",
    "train_df['h'] = -1\n",
    "\n",
    "def expand_bbox(x):\n",
    "    r = np.array(re.findall(\"([0-9]+[.]?[0-9]*)\", x))\n",
    "    if len(r) == 0:\n",
    "        r = [-1, -1, -1, -1]\n",
    "    return r\n",
    "\n",
    "train_df[['x', 'y', 'w', 'h']] = np.stack(train_df['bbox'].apply(lambda x: expand_bbox(x)))\n",
    "train_df.drop(columns=['bbox'], inplace=True)\n",
    "train_df['x'] = train_df['x'].astype(np.float)\n",
    "train_df['y'] = train_df['y'].astype(np.float)\n",
    "train_df['w'] = train_df['w'].astype(np.float)\n",
    "train_df['h'] = train_df['h'].astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = train_df['image_id'].unique()\n",
    "valid_ids = image_ids[-665:]\n",
    "train_ids = image_ids[:-665]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = train_df[train_df['image_id'].isin(valid_ids)]\n",
    "train_df = train_df[train_df['image_id'].isin(train_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25006, 8), (122787, 8))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.shape, train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WheatDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, image_dir, transforms=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_ids = dataframe['image_id'].unique()\n",
    "        self.df = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "\n",
    "        image_id = self.image_ids[index]\n",
    "        records = self.df[self.df['image_id'] == image_id]\n",
    "\n",
    "        image = cv2.imread(f'{self.image_dir}/{image_id}.jpg', cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "\n",
    "        boxes = records[['x', 'y', 'w', 'h']].values\n",
    "        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n",
    "        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n",
    "        \n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        area = torch.as_tensor(area, dtype=torch.float32)\n",
    "\n",
    "        # there is only one class\n",
    "        labels = torch.ones((records.shape[0],), dtype=torch.int64)\n",
    "        \n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((records.shape[0],), dtype=torch.int64)\n",
    "        \n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "        # target['masks'] = None\n",
    "        target['image_id'] = torch.tensor([index])\n",
    "        target['area'] = area\n",
    "        target['iscrowd'] = iscrowd\n",
    "\n",
    "        if self.transforms:\n",
    "            sample = {\n",
    "                'image': image,\n",
    "                'bboxes': target['boxes'],\n",
    "                'labels': labels\n",
    "            }\n",
    "            sample = self.transforms(**sample)\n",
    "            image = sample['image']\n",
    "            \n",
    "            target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
    "\n",
    "        return image, target, image_id\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.image_ids.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Albumentations\n",
    "def get_train_transform():\n",
    "    return A.Compose([\n",
    "        A.Flip(0.5),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
    "\n",
    "def get_valid_transform():\n",
    "    return A.Compose([\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a model; pre-trained on COCO\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, pretrained_backbone=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform()\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(original_name=FrozenBatchNorm2d)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign()\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "num_classes = 2  # 1 class (wheat) + background\n",
    "\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "# Load the trained weights\n",
    "model.load_state_dict(torch.load(WEIGHTS_FILE))\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_dataset = WheatDataset(train_df[:100], DIR_TRAIN, get_train_transform())\n",
    "valid_dataset = WheatDataset(valid_df[:50], DIR_TRAIN, get_valid_transform())\n",
    "\n",
    "\n",
    "# split the dataset in train and test set\n",
    "indices = torch.randperm(len(train_dataset)).tolist()\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=28,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "valid_data_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_image_precisions = []\n",
    "iou_thresholds = [x for x in np.arange(0.5, 0.76, 0.05)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAP calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def calculate_iou(gt, pr, form='pascal_voc') -> float:\n",
    "    \"\"\"Calculates the Intersection over Union.\n",
    "\n",
    "    Args:\n",
    "        gt: (np.ndarray[Union[int, float]]) coordinates of the ground-truth box\n",
    "        pr: (np.ndarray[Union[int, float]]) coordinates of the prdected box\n",
    "        form: (str) gt/pred coordinates format\n",
    "            - pascal_voc: [xmin, ymin, xmax, ymax]\n",
    "            - coco: [xmin, ymin, w, h]\n",
    "    Returns:\n",
    "        (float) Intersection over union (0.0 <= iou <= 1.0)\n",
    "    \"\"\"\n",
    "    if form == 'coco':\n",
    "        gt = gt.copy()\n",
    "        pr = pr.copy()\n",
    "\n",
    "        gt[2] = gt[0] + gt[2]\n",
    "        gt[3] = gt[1] + gt[3]\n",
    "        pr[2] = pr[0] + pr[2]\n",
    "        pr[3] = pr[1] + pr[3]\n",
    "\n",
    "    # Calculate overlap area\n",
    "    dx = min(gt[2], pr[2]) - max(gt[0], pr[0]) + 1\n",
    "    \n",
    "    if dx < 0:\n",
    "        return 0.0\n",
    "    \n",
    "    dy = min(gt[3], pr[3]) - max(gt[1], pr[1]) + 1\n",
    "\n",
    "    if dy < 0:\n",
    "        return 0.0\n",
    "\n",
    "    overlap_area = dx * dy\n",
    "\n",
    "    # Calculate union area\n",
    "    union_area = (\n",
    "            (gt[2] - gt[0] + 1) * (gt[3] - gt[1] + 1) +\n",
    "            (pr[2] - pr[0] + 1) * (pr[3] - pr[1] + 1) -\n",
    "            overlap_area\n",
    "    )\n",
    "\n",
    "    return overlap_area / union_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def find_best_match(gts, pred, pred_idx, threshold = 0.5, form = 'pascal_voc', ious=None) -> int:\n",
    "    \"\"\"Returns the index of the 'best match' between the\n",
    "    ground-truth boxes and the prediction. The 'best match'\n",
    "    is the highest IoU. (0.0 IoUs are ignored).\n",
    "\n",
    "    Args:\n",
    "        gts: (List[List[Union[int, float]]]) Coordinates of the available ground-truth boxes\n",
    "        pred: (List[Union[int, float]]) Coordinates of the predicted box\n",
    "        pred_idx: (int) Index of the current predicted box\n",
    "        threshold: (float) Threshold\n",
    "        form: (str) Format of the coordinates\n",
    "        ious: (np.ndarray) len(gts) x len(preds) matrix for storing calculated ious.\n",
    "\n",
    "    Return:\n",
    "        (int) Index of the best match GT box (-1 if no match above threshold)\n",
    "    \"\"\"\n",
    "    best_match_iou = -np.inf\n",
    "    best_match_idx = -1\n",
    "\n",
    "    for gt_idx in range(len(gts)):\n",
    "        \n",
    "        if gts[gt_idx][0] < 0:\n",
    "            # Already matched GT-box\n",
    "            continue\n",
    "        \n",
    "        iou = -1 if ious is None else ious[gt_idx][pred_idx]\n",
    "\n",
    "        if iou < 0:\n",
    "            iou = calculate_iou(gts[gt_idx], pred, form=form)\n",
    "            \n",
    "            if ious is not None:\n",
    "                ious[gt_idx][pred_idx] = iou\n",
    "\n",
    "        if iou < threshold:\n",
    "            continue\n",
    "\n",
    "        if iou > best_match_iou:\n",
    "            best_match_iou = iou\n",
    "            best_match_idx = gt_idx\n",
    "\n",
    "    return best_match_idx\n",
    "\n",
    "@jit(nopython=True)\n",
    "def calculate_precision(gts, preds, threshold = 0.5, form = 'coco', ious=None) -> float:\n",
    "    \"\"\"Calculates precision for GT - prediction pairs at one threshold.\n",
    "\n",
    "    Args:\n",
    "        gts: (List[List[Union[int, float]]]) Coordinates of the available ground-truth boxes\n",
    "        preds: (List[List[Union[int, float]]]) Coordinates of the predicted boxes,\n",
    "               sorted by confidence value (descending)\n",
    "        threshold: (float) Threshold\n",
    "        form: (str) Format of the coordinates\n",
    "        ious: (np.ndarray) len(gts) x len(preds) matrix for storing calculated ious.\n",
    "\n",
    "    Return:\n",
    "        (float) Precision\n",
    "    \"\"\"\n",
    "    n = len(preds)\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    \n",
    "    # for pred_idx, pred in enumerate(preds_sorted):\n",
    "    for pred_idx in range(n):\n",
    "\n",
    "        best_match_gt_idx = find_best_match(gts, preds[pred_idx], pred_idx,\n",
    "                                            threshold=threshold, form=form, ious=ious)\n",
    "\n",
    "        if best_match_gt_idx >= 0:\n",
    "            # True positive: The predicted box matches a gt box with an IoU above the threshold.\n",
    "            tp += 1\n",
    "            # Remove the matched GT box\n",
    "            gts[best_match_gt_idx] = -1\n",
    "\n",
    "        else:\n",
    "            # No match\n",
    "            # False positive: indicates a predicted box had no associated gt box.\n",
    "            fp += 1\n",
    "\n",
    "    # False negative: indicates a gt box had no associated predicted box.\n",
    "    fn = (gts.sum(axis=1) > 0).sum()\n",
    "\n",
    "    return tp / (tp + fp + fn)\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def calculate_image_precision(gts, preds, thresholds = (0.5, ), form = 'coco') -> float:\n",
    "    \"\"\"Calculates image precision.\n",
    "\n",
    "    Args:\n",
    "        gts: (List[List[Union[int, float]]]) Coordinates of the available ground-truth boxes\n",
    "        preds: (List[List[Union[int, float]]]) Coordinates of the predicted boxes,\n",
    "               sorted by confidence value (descending)\n",
    "        thresholds: (float) Different thresholds\n",
    "        form: (str) Format of the coordinates\n",
    "\n",
    "    Return:\n",
    "        (float) Precision\n",
    "    \"\"\"\n",
    "    n_threshold = len(thresholds)\n",
    "    image_precision = 0.0\n",
    "    \n",
    "    ious = np.ones((len(gts), len(preds))) * -1\n",
    "    # ious = None\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        precision_at_threshold = calculate_precision(gts.copy(), preds, threshold=threshold,\n",
    "                                                     form=form, ious=ious)\n",
    "        image_precision += precision_at_threshold / n_threshold\n",
    "\n",
    "    return image_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_id: bbce58f71\n",
      "scores: [0.99686426 0.9966024  0.9957345  0.9953365  0.9952716  0.99508375\n",
      " 0.9947802  0.99468046 0.9933749  0.992993   0.9929323  0.9924238\n",
      " 0.9923258  0.99190485 0.99023527 0.99004984 0.9899067  0.98919463\n",
      " 0.9884278  0.9867121  0.98631895 0.984937   0.9844738  0.9841298\n",
      " 0.98174804 0.9814953  0.97958666 0.97730404 0.9770215  0.97695816\n",
      " 0.9679233  0.9672326  0.9626706  0.96222174 0.9561973  0.95138264\n",
      " 0.9457221  0.9418765  0.9223838  0.8865785  0.8547953  0.7260833\n",
      " 0.54316944 0.51430106 0.29412213 0.28823933 0.15232734 0.13994728\n",
      " 0.09286306 0.09246738 0.06437422]\n",
      "preds: [[672  86 147 100]\n",
      " [931 910  92 109]\n",
      " [312 584 130  99]\n",
      " [789 646 148  72]\n",
      " [581  54 118  76]\n",
      " [ 60   3  88  68]\n",
      " [343 831 103 115]\n",
      " [320 921  88 101]\n",
      " [522 458 140  77]\n",
      " [479 314 144  73]\n",
      " [891 173 105  65]\n",
      " [944 802  79 103]\n",
      " [158 302  94  97]\n",
      " [212 699  96  76]\n",
      " [718 415 130  96]\n",
      " [257 379  94  68]\n",
      " [770 319 151  70]\n",
      " [427   7 106  72]\n",
      " [192 473  88  72]\n",
      " [555 721 151  77]\n",
      " [948 703  75  75]\n",
      " [698 889 129 104]\n",
      " [919 478 104  71]\n",
      " [471 901  97 106]\n",
      " [788 403 133  79]\n",
      " [399 561  82  65]\n",
      " [218 543  98  64]\n",
      " [587 558 134  70]\n",
      " [  0 683 133  93]\n",
      " [  0 315  89  78]\n",
      " [765 267 110  61]\n",
      " [535 262 178  72]\n",
      " [320 131 114  68]\n",
      " [910 388 112  66]\n",
      " [  0 259  79  71]\n",
      " [368 163 100  65]\n",
      " [  3 747  85  77]\n",
      " [146 925  80  72]\n",
      " [791 878 102 123]\n",
      " [657 533 136  77]\n",
      " [338 141 121  80]\n",
      " [979 223  44  54]\n",
      " [812 939  92  82]\n",
      " [633 504 149  85]\n",
      " [762 279 146  97]\n",
      " [460 993 101  30]\n",
      " [710 898 180 116]\n",
      " [494 585  54  56]\n",
      " [ 62 665  64  47]\n",
      " [ 71 634  71  38]\n",
      " [808 519  33  85]]\n",
      "preds_sorted_idx: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50]\n",
      "preds_sorted: [[672  86 147 100]\n",
      " [931 910  92 109]\n",
      " [312 584 130  99]\n",
      " [789 646 148  72]\n",
      " [581  54 118  76]\n",
      " [ 60   3  88  68]\n",
      " [343 831 103 115]\n",
      " [320 921  88 101]\n",
      " [522 458 140  77]\n",
      " [479 314 144  73]\n",
      " [891 173 105  65]\n",
      " [944 802  79 103]\n",
      " [158 302  94  97]\n",
      " [212 699  96  76]\n",
      " [718 415 130  96]\n",
      " [257 379  94  68]\n",
      " [770 319 151  70]\n",
      " [427   7 106  72]\n",
      " [192 473  88  72]\n",
      " [555 721 151  77]\n",
      " [948 703  75  75]\n",
      " [698 889 129 104]\n",
      " [919 478 104  71]\n",
      " [471 901  97 106]\n",
      " [788 403 133  79]\n",
      " [399 561  82  65]\n",
      " [218 543  98  64]\n",
      " [587 558 134  70]\n",
      " [  0 683 133  93]\n",
      " [  0 315  89  78]\n",
      " [765 267 110  61]\n",
      " [535 262 178  72]\n",
      " [320 131 114  68]\n",
      " [910 388 112  66]\n",
      " [  0 259  79  71]\n",
      " [368 163 100  65]\n",
      " [  3 747  85  77]\n",
      " [146 925  80  72]\n",
      " [791 878 102 123]\n",
      " [657 533 136  77]\n",
      " [338 141 121  80]\n",
      " [979 223  44  54]\n",
      " [812 939  92  82]\n",
      " [633 504 149  85]\n",
      " [762 279 146  97]\n",
      " [460 993 101  30]\n",
      " [710 898 180 116]\n",
      " [494 585  54  56]\n",
      " [ 62 665  64  47]\n",
      " [ 71 634  71  38]\n",
      " [808 519  33  85]]\n",
      "validation_image_precisions: [0.6327148178022566, 0.584408375222235, 0.6327148178022566, 0.584408375222235, 0.6327148178022566, 0.584408375222235, 0.6327148178022566, 0.584408375222235, 0.6327148178022566]\n",
      "image_id: b45096c1e\n",
      "scores: [0.9978861  0.99733526 0.9972959  0.99657637 0.99638945 0.996092\n",
      " 0.99602437 0.99593395 0.9958395  0.99563885 0.9952434  0.9945363\n",
      " 0.9941765  0.9939394  0.9934796  0.9930754  0.99267817 0.9923879\n",
      " 0.9920555  0.9912445  0.9911773  0.99068797 0.98994    0.9898499\n",
      " 0.9896199  0.98931634 0.98854524 0.9874129  0.9870279  0.9861646\n",
      " 0.9820056  0.9811948  0.97835857 0.9662765  0.95988834 0.9551595\n",
      " 0.95004517 0.92706    0.75104165 0.6812985  0.6769283  0.6714741\n",
      " 0.6513689  0.6079291  0.39719546 0.3923166  0.32819673 0.24736962\n",
      " 0.23971102 0.22582507 0.20305714 0.18849717 0.13029417 0.12027658\n",
      " 0.11409982 0.09349917 0.08973981 0.08554473 0.07899214 0.07878455\n",
      " 0.07164887 0.06103193]\n",
      "preds: [[740 351 189  90]\n",
      " [882 772 111 196]\n",
      " [503 479 212 198]\n",
      " [421 290 104 137]\n",
      " [770 749 102  95]\n",
      " [ 15 691  76 131]\n",
      " [ 42 547  99  96]\n",
      " [479 806  93 164]\n",
      " [  0 861  70 137]\n",
      " [ 24   0 116  63]\n",
      " [931 646  92 111]\n",
      " [269 182 101  93]\n",
      " [612 269 153  67]\n",
      " [ 31 466  73  76]\n",
      " [569  50 158  73]\n",
      " [907 119  86  65]\n",
      " [341 918  77 102]\n",
      " [ 83 423  85  91]\n",
      " [929  33  94  57]\n",
      " [307  11  78  78]\n",
      " [484 263 108  67]\n",
      " [723 261 210  81]\n",
      " [668 553 114  61]\n",
      " [395 157  82  92]\n",
      " [269 846  90 117]\n",
      " [502 148  86  81]\n",
      " [959  81  64  55]\n",
      " [  0 231  86  72]\n",
      " [403  58  72  74]\n",
      " [569 182 118  67]\n",
      " [ 43 843 105 138]\n",
      " [372 218  98  77]\n",
      " [642 783  66  97]\n",
      " [729 937  65  85]\n",
      " [439 907 112 116]\n",
      " [114 862  96 156]\n",
      " [504   4  96  48]\n",
      " [248 875  77 134]\n",
      " [583 897 123 108]\n",
      " [  0 274  44  60]\n",
      " [575  64 120  86]\n",
      " [454   0  86  34]\n",
      " [  0 321  42  77]\n",
      " [ 16 850  96 140]\n",
      " [310 947  69  76]\n",
      " [473 949 125  73]\n",
      " [598 105  72  48]\n",
      " [256 984  69  39]\n",
      " [ 12 841 193 169]\n",
      " [  0 277  48 104]\n",
      " [143 932  73  91]\n",
      " [255 901 115 118]\n",
      " [293 914 377 109]\n",
      " [569 552 157 120]\n",
      " [517 963  69  57]\n",
      " [563 726  64  59]\n",
      " [716 632  46  57]\n",
      " [531 708 121  97]\n",
      " [ 13 856 388 158]\n",
      " [269 967  67  54]\n",
      " [626 728  56  69]\n",
      " [636 552 135 106]]\n",
      "preds_sorted_idx: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61]\n",
      "preds_sorted: [[740 351 189  90]\n",
      " [882 772 111 196]\n",
      " [503 479 212 198]\n",
      " [421 290 104 137]\n",
      " [770 749 102  95]\n",
      " [ 15 691  76 131]\n",
      " [ 42 547  99  96]\n",
      " [479 806  93 164]\n",
      " [  0 861  70 137]\n",
      " [ 24   0 116  63]\n",
      " [931 646  92 111]\n",
      " [269 182 101  93]\n",
      " [612 269 153  67]\n",
      " [ 31 466  73  76]\n",
      " [569  50 158  73]\n",
      " [907 119  86  65]\n",
      " [341 918  77 102]\n",
      " [ 83 423  85  91]\n",
      " [929  33  94  57]\n",
      " [307  11  78  78]\n",
      " [484 263 108  67]\n",
      " [723 261 210  81]\n",
      " [668 553 114  61]\n",
      " [395 157  82  92]\n",
      " [269 846  90 117]\n",
      " [502 148  86  81]\n",
      " [959  81  64  55]\n",
      " [  0 231  86  72]\n",
      " [403  58  72  74]\n",
      " [569 182 118  67]\n",
      " [ 43 843 105 138]\n",
      " [372 218  98  77]\n",
      " [642 783  66  97]\n",
      " [729 937  65  85]\n",
      " [439 907 112 116]\n",
      " [114 862  96 156]\n",
      " [504   4  96  48]\n",
      " [248 875  77 134]\n",
      " [583 897 123 108]\n",
      " [  0 274  44  60]\n",
      " [575  64 120  86]\n",
      " [454   0  86  34]\n",
      " [  0 321  42  77]\n",
      " [ 16 850  96 140]\n",
      " [310 947  69  76]\n",
      " [473 949 125  73]\n",
      " [598 105  72  48]\n",
      " [256 984  69  39]\n",
      " [ 12 841 193 169]\n",
      " [  0 277  48 104]\n",
      " [143 932  73  91]\n",
      " [255 901 115 118]\n",
      " [293 914 377 109]\n",
      " [569 552 157 120]\n",
      " [517 963  69  57]\n",
      " [563 726  64  59]\n",
      " [716 632  46  57]\n",
      " [531 708 121  97]\n",
      " [ 13 856 388 158]\n",
      " [269 967  67  54]\n",
      " [626 728  56  69]\n",
      " [636 552 135 106]]\n",
      "validation_image_precisions: [0.6327148178022566, 0.584408375222235, 0.6327148178022566, 0.584408375222235, 0.6327148178022566, 0.584408375222235, 0.6327148178022566, 0.584408375222235, 0.6327148178022566, 0.584408375222235]\n",
      "Validation IOU: 0.6086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for images, targets, image_ids in tqdm(valid_data_loader):\n",
    "    \n",
    "        images = list(image.to(device) for image in images)\n",
    "        outputs = model(images)\n",
    "        for i, image in enumerate(images):\n",
    "    \n",
    "            preds = outputs[i]['boxes'].data.cpu().numpy()\n",
    "            scores = outputs[i]['scores'].data.cpu().numpy()\n",
    "            image_id = image_ids[i]\n",
    "            print('image_id:',image_id)\n",
    "            print('scores:',scores)\n",
    "            preds[:, 2] = preds[:, 2] - preds[:, 0]\n",
    "            preds[:, 3] = preds[:, 3] - preds[:, 1]\n",
    "            \n",
    "            gt_boxes = valid_df[valid_df['image_id'] == image_id][['x', 'y', 'w', 'h']].values\n",
    "            gt_boxes = gt_boxes.astype(np.int)\n",
    "            #print('preds:',preds.astype(np.int))\n",
    "            preds_sorted_idx = np.argsort(scores)[::-1]\n",
    "            #print('preds_sorted_idx:',preds_sorted_idx)\n",
    "            preds_sorted = preds[preds_sorted_idx].astype(np.int)\n",
    "            #print('preds_sorted:',preds_sorted)\n",
    "            image_precision = calculate_image_precision(preds_sorted,\n",
    "                                                        gt_boxes,\n",
    "                                                        thresholds=iou_thresholds,\n",
    "                                                        form='coco')\n",
    "            validation_image_precisions.append(image_precision)\n",
    "            print('validation_image_precisions:',validation_image_precisions)\n",
    "print(\"Validation IOU: {0:.4f}\".format(np.mean(validation_image_precisions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[430,   0, 142,  75],\n",
       "       [255, 377, 100,  69],\n",
       "       [788, 634, 146,  77],\n",
       "       [344, 836, 102, 110],\n",
       "       [217, 694, 107,  85],\n",
       "       [885, 174, 115,  64],\n",
       "       [752, 263, 160,  64],\n",
       "       [  2, 685, 122, 100],\n",
       "       [709, 901, 117,  96],\n",
       "       [587,  49, 120,  89],\n",
       "       [519, 455, 141,  80],\n",
       "       [547, 716, 162,  80],\n",
       "       [195, 482,  87,  66],\n",
       "       [932, 473,  92,  77],\n",
       "       [480, 911,  95, 105],\n",
       "       [  0, 801,   5,  79],\n",
       "       [309, 573, 128, 107],\n",
       "       [671,  83, 161, 110],\n",
       "       [ 57,   0, 100,  66],\n",
       "       [314, 127, 144,  77],\n",
       "       [157, 312, 103,  87],\n",
       "       [217, 539,  94,  64],\n",
       "       [910, 389, 113,  73],\n",
       "       [465, 314, 163,  63],\n",
       "       [808, 408, 128,  75],\n",
       "       [626, 493, 174, 121],\n",
       "       [394, 558,  84,  71],\n",
       "       [  0, 326,  94,  81],\n",
       "       [721, 412, 130, 104],\n",
       "       [583, 555, 154,  67],\n",
       "       [  0, 742, 102,  80],\n",
       "       [310, 922, 100, 102],\n",
       "       [795, 880, 114, 142],\n",
       "       [770, 325, 151,  61],\n",
       "       [376, 153, 120,  79],\n",
       "       [545, 253, 192,  92],\n",
       "       [944, 794,  79, 121],\n",
       "       [942, 705,  82,  71],\n",
       "       [143, 933,  91,  56],\n",
       "       [  0, 248,  77,  86],\n",
       "       [734, 879, 122,  89]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample_id = '1ef16dab1'\n",
    "sample_id = 'bbce58f71'\n",
    "gt_boxes = valid_df[valid_df['image_id'] == sample_id][['x', 'y', 'w', 'h']].values\n",
    "gt_boxes = gt_boxes.astype(np.int)\n",
    "\n",
    "# Ground-truth boxes of our sample\n",
    "gt_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds:[[672,  86, 147, 100],\n",
    " [931, 910,  92, 109],\n",
    " [312, 584, 130,  99],\n",
    " [789, 646, 148,  72],\n",
    " [581,  54, 118,  76],\n",
    " [ 60,   3,  88,  68],\n",
    " [343, 831, 103, 115],\n",
    " [320, 921,  88, 101],\n",
    " [522, 458, 140,  77],\n",
    " [479, 314, 144,  73],\n",
    " [891, 173, 105,  65],\n",
    " [944, 802,  79, 103],\n",
    " [158, 302,  94,  97],\n",
    " [212, 699,  96,  76],\n",
    " [718, 415, 130,  96],\n",
    " [257, 379,  94,  68],\n",
    " [770, 319, 151,  70],\n",
    " [427,   7, 106,  72],\n",
    " [192, 473,  88,  72],\n",
    " [555, 721, 151,  77],\n",
    " [948, 703,  75,  75],\n",
    " [698, 889, 129, 104],\n",
    " [919, 478, 104,  71],\n",
    " [471, 901,  97, 106],\n",
    " [788, 403, 133,  79],\n",
    " [399, 561,  82,  65],\n",
    " [218, 543,  98,  64],\n",
    " [587, 558, 134,  70],\n",
    " [  0, 683, 133,  93],\n",
    " [  0, 315,  89,  78],\n",
    " [765, 267, 110,  61],\n",
    " [535, 262, 178,  72],\n",
    " [320, 131, 114,  68],\n",
    " [910, 388, 112,  66],\n",
    " [  0, 259,  79,  71],\n",
    " [368, 163, 100,  65],\n",
    " [  3, 747,  85,  77],\n",
    " [146, 925,  80,  72],\n",
    " [791, 878, 102, 123],\n",
    " [657, 533, 136,  77],\n",
    " [338, 141, 121,  80],\n",
    " [979, 223,  44,  54],\n",
    " [812, 939,  92,  82],\n",
    " [633, 504, 149,  85],\n",
    " [762, 279, 146,  97],\n",
    " [460, 993, 101,  30],\n",
    " [710, 898, 180, 116],\n",
    " [494, 585,  54,  56],\n",
    " [ 62, 665,  64,  47],\n",
    " [ 71, 634,  71,  38],\n",
    " [808, 519,  33,  85]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.array([0.99686426, 0.9966024, 0.9957345, 0.9953365, 0.9952716, 0.99508375,\n",
    " 0.9947802,  0.99468046, 0.9933749,  0.992993,   0.9929323,  0.9924238,\n",
    " 0.9923258,  0.99190485, 0.99023527, 0.99004984, 0.9899067,  0.98919463,\n",
    " 0.9884278,  0.9867121,  0.98631895, 0.984937,   0.9844738,  0.9841298,\n",
    " 0.98174804, 0.9814953,  0.97958666, 0.97730404, 0.9770215,  0.97695816,\n",
    " 0.9679233,  0.9672326,  0.9626706,  0.96222174, 0.9561973,  0.95138264,\n",
    " 0.9457221,  0.9418765,  0.9223838,  0.8865785,  0.8547953,  0.7260833,\n",
    " 0.54316944, 0.51430106, 0.29412213, 0.28823933, 0.15232734, 0.13994728,\n",
    " 0.09286306, 0.09246738, 0.06437422])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort highest confidence -> lowest confidence\n",
    "preds_sorted_idx = np.argsort(scores)[::-1]\n",
    "preds_sorted = preds[preds_sorted_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 38, 547, 100,  87],\n",
       "       [266, 181,  97,  87],\n",
       "       [958,  80,  66,  52],\n",
       "       [732, 348, 192,  84],\n",
       "       [ 20,   0, 115,  53],\n",
       "       [512, 479, 190, 195],\n",
       "       [422, 294, 108, 135],\n",
       "       [488, 261,  98,  64],\n",
       "       [501, 143,  90,  79],\n",
       "       [ 32, 472,  71,  70],\n",
       "       [614, 266, 154,  64],\n",
       "       [910, 117,  83,  73],\n",
       "       [570,  46, 154,  84],\n",
       "       [302,  10,  82,  71],\n",
       "       [880, 775, 108, 182],\n",
       "       [ 42, 843, 121, 149],\n",
       "       [ 15, 688,  72, 118],\n",
       "       [483, 808,  82, 149],\n",
       "       [  0, 862,  56, 121],\n",
       "       [770, 747,  90,  90],\n",
       "       [563, 174, 115,  71],\n",
       "       [714, 256, 228,  84],\n",
       "       [401,  61,  75,  64],\n",
       "       [419,   0, 121,  37],\n",
       "       [371, 204,  94,  82],\n",
       "       [ 81, 425,  84,  95],\n",
       "       [  0, 292,  39,  98],\n",
       "       [670, 547, 110,  67],\n",
       "       [283, 852,  78, 120],\n",
       "       [391, 151,  77,  97],\n",
       "       [588, 888, 103,  95],\n",
       "       [632, 780,  77,  87],\n",
       "       [  0, 227,  76,  69],\n",
       "       [586,  81,  69,  72],\n",
       "       [499,   5, 100,  48],\n",
       "       [936,  28,  85,  70],\n",
       "       [106, 868, 102, 151],\n",
       "       [262, 856,  74, 148],\n",
       "       [417, 901, 141, 123],\n",
       "       [724, 939,  79,  85],\n",
       "       [946, 651,  78,  92],\n",
       "       [342, 925,  70,  99]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_boxes.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision at threshold 0.5: 0.7885\n"
     ]
    }
   ],
   "source": [
    "precision = calculate_precision(gt_boxes.copy(), preds_sorted, threshold=0.5, form='coco')\n",
    "print(\"Precision at threshold 0.5: {0:.4f}\".format(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:badeda]",
   "language": "python",
   "name": "conda-env-badeda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
